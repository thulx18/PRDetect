{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_height(token):\n",
    "    if not list(token.children):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + max(calculate_height(child) for child in token.children)\n",
    "    \n",
    "def count_subtree_nodes(token):\n",
    "    count = 1\n",
    "    for child in token.children:\n",
    "        count += count_subtree_nodes(child)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_analyze(file_name):\n",
    "    all_depth = list()\n",
    "    root_depth = list()\n",
    "    root_nodes = list()\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    with open(f\"original_text/{file_name}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            line = json.loads(line)\n",
    "            text = line['text']\n",
    "            doc = nlp(text)\n",
    "            for token in doc:\n",
    "                depth = 0\n",
    "                current_token = token\n",
    "                while current_token.head != current_token:\n",
    "                    depth += 1\n",
    "                    current_token = current_token.head\n",
    "                all_depth.append(depth)\n",
    "                if token.dep_ == \"ROOT\":\n",
    "                    root_depth.append(calculate_height(token))\n",
    "                    root_nodes.append(count_subtree_nodes(token))\n",
    "    avg_all_depth = sum(all_depth) / len(all_depth)\n",
    "    avg_root_depth = sum(root_depth) / len(root_depth)\n",
    "    avg_root_nodes = sum(root_nodes) / len(root_nodes)\n",
    "    print(avg_all_depth, avg_root_depth, avg_root_nodes)\n",
    "    with open(f\"output/depth_analyze_result.txt\", \"a\", encoding='utf=8') as w:\n",
    "        w.write(f\"{file_name}\\t{avg_all_depth}\\t{avg_root_depth}\\t{avg_root_nodes}\\n\")\n",
    "    \n",
    "    plt.hist(all_depth, bins=(max(all_depth)- min(all_depth)))\n",
    "    plt.xlabel('Depth of Nodes')\n",
    "    plt.ylabel('Frequency')\n",
    "    png_name = file_name.replace(\".json\", \"_all_depth_.png\")\n",
    "    plt.savefig(f\"output/{png_name}\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.hist(root_nodes, bins=(max(root_nodes)- min(root_nodes)))\n",
    "    plt.xlabel('Number of Nodes')\n",
    "    plt.ylabel('Frequency')\n",
    "    png_name = file_name.replace(\".json\", \"_root_nodes.png\")\n",
    "    plt.savefig(f\"output/{png_name}\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.hist(root_depth, bins=(max(root_depth)- min(root_depth)))\n",
    "    plt.xlabel('Depth of Root Nodes')\n",
    "    plt.ylabel('Frequency')\n",
    "    png_name = file_name.replace(\".json\", \"_root_depth.png\")\n",
    "    plt.savefig(f\"output/{png_name}\")\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 67.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0027404768429706 5.330383480825959 21.52802359882006\n"
     ]
    }
   ],
   "source": [
    "file_list = ['hc3_train.json', 'hc3_val.json', 'hc3_test.json',\n",
    "             'grover_train_split.json', 'grover_dev_split.json', 'grover_test_split.json',\n",
    "             'gpt3.5_mixed_train_split.json', \"gpt3.5_mixed_val_split.json\", \"gpt3.5_mixed_test_split.json\"\n",
    "             ]\n",
    "for file in file_list:\n",
    "    depth_analyze(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
